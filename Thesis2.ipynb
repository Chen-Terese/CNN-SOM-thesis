{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Pz26pDnNvl-eyqa19iGSra_npzd-eBim",
      "authorship_tag": "ABX9TyNBYCFz39nYJV8v9zoOVao1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chen-Terese/CNN-SOM-code/blob/main/Thesis2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jAMdVCB94_DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Required Libraries**"
      ],
      "metadata": {
        "id": "lxbTg_jp7vLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SWynW35UuuIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the Data**"
      ],
      "metadata": {
        "id": "ixz9lqpJ7_yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/MRI dataset/Alzheimer_MRI_4_classes_dataset'\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "eC-KBziqhdmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_PATH,\n",
        "    label_mode=None,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrniEmKdQlKd",
        "outputId": "94178dd3-6aa4-4c5a-ee0b-ffd364d69337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6400 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation**"
      ],
      "metadata": {
        "id": "MPBIbSmX8FaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image):\n",
        "    # image: (224, 224, 3) from image_dataset_from_directory\n",
        "    # Convert to grayscale â†’ (224, 224, 1)\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    # Ensure static shape\n",
        "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 1])\n",
        "    return image"
      ],
      "metadata": {
        "id": "5IhHGQO6vy68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset of paired augmented images\n",
        "def prepare_simclr_dataset(input_dataset):\n",
        "    def _augment(image):\n",
        "        return augment(image), augment(image)\n",
        "\n",
        "    dataset = (\n",
        "        input_dataset\n",
        "        .unbatch()\n",
        "        .map(_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(BATCH_SIZE)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "rE76GC5GaDBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the ResNet50 Model**"
      ],
      "metadata": {
        "id": "58Uuirin8nQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "rflCGrXCwHsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop aggressive downsampling\n",
        "base.layers[2].strides = (1, 1)  # first conv stride 1\n",
        "x = base.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "encoder = tf.keras.Model(base.input, x, name=\"MRI_Encoder\")"
      ],
      "metadata": {
        "id": "17OIuaAywNwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simclr Projection Head**"
      ],
      "metadata": {
        "id": "XCJlhLv9_nxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple projection head\n",
        "proj_head = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128)\n",
        "], name=\"projection\")"
      ],
      "metadata": {
        "id": "sv1twRAiwWEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full SimCLR model\n",
        "inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 1))\n",
        "features = encoder(inputs)\n",
        "projections = proj_head(features)\n",
        "simclr_model = tf.keras.Model(inputs, projections)"
      ],
      "metadata": {
        "id": "yLOw8N6rwbSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss**"
      ],
      "metadata": {
        "id": "ri_ec1BX_1qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple NT-Xent loss\n",
        "def simclr_loss(z_i, z_j, temperature=0.1):\n",
        "    z_i = tf.math.l2_normalize(z_i, axis=1)\n",
        "    z_j = tf.math.l2_normalize(z_j, axis=1)\n",
        "    z = tf.concat([z_i, z_j], axis=0)\n",
        "    similarity = tf.matmul(z, z, transpose_b=True) / temperature\n",
        "    batch_size = tf.shape(z_i)[0]\n",
        "    labels = tf.range(batch_size)\n",
        "    labels = tf.concat([labels + batch_size, labels], axis=0)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(labels, similarity)\n",
        "    return loss\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(3e-4)"
      ],
      "metadata": {
        "id": "SXikev12wdFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(view1, view2):\n",
        "    with tf.GradientTape() as tape:\n",
        "        z1 = simclr_model(view1, training=True)\n",
        "        z2 = simclr_model(view2, training=True)\n",
        "        loss = simclr_loss(z1, z2)\n",
        "    grads = tape.gradient(loss, simclr_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, simclr_model.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "F57ezWRqwzSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "uaXgsJJBAWuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== TRAINING STARTS HERE ==================\n",
        "print(\"Training in progress...\")\n",
        "\n",
        "# Prepare the dataset\n",
        "simclr_training_dataset = prepare_simclr_dataset(dataset)\n",
        "\n",
        "# Training loop with debug prints for shapes\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    for batch in simclr_training_dataset:\n",
        "        # Unpack batch properly: batch is a tuple of two tensors (view1s, view2s)\n",
        "        view1, view2 = batch\n",
        "\n",
        "        # Check shapes to make sure they are correct\n",
        "        # print(f\"view1 shape: {view1.shape}, view2 shape: {view2.shape}\")\n",
        "\n",
        "        loss = train_step(view1, view2)\n",
        "        epoch_loss_avg.update_state(loss)\n",
        "    print(f\"Epoch: {epoch + 1}, loss: {epoch_loss_avg.result().numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrIt6qwww9Ac",
        "outputId": "64bf0fa4-b941-46f9-880b-fc27089f2b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training in progress...\n",
            "Epoch: 1, loss: 0.8377034068107605\n",
            "Epoch: 2, loss: 0.738017737865448\n",
            "Epoch: 3, loss: 0.7256376147270203\n",
            "Epoch: 4, loss: 0.7225548624992371\n",
            "Epoch: 5, loss: 0.7152161598205566\n",
            "Epoch: 6, loss: 0.7131702303886414\n",
            "Epoch: 7, loss: 0.7148420810699463\n",
            "Epoch: 8, loss: 0.7138302326202393\n",
            "Epoch: 9, loss: 0.7267529368400574\n"
          ]
        }
      ]
    }
  ]
}